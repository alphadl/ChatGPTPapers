# ChatGPTPapers
Must-read papers, related blogs and API tools on the pre-training and tuning methods for ChatGPT.

## Papers 
1. 【GPT-1】**Improving Language Understanding by Generative Pre-Training.**

    *Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever* [[pdf](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)] 2018.6  
1. 【GPT-2】**Language Models are Unsupervised Multitask Learners.** 

    *Alec Radford, Jeff Wu, Rewon Child, D. Luan, Dario Amodei, Ilya Sutskeve* [[pdf](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)] 2019.2  
1. 【GPT-3】**Language Models are Few-Shot Learners.** 
    
    *Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei* [[pdf](https://arxiv.org/abs/2005.14165)] 2020.5
1. 【InstructGPT】**Training language models to follow instructions with human feedback.**

    *Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, Ryan Lowe* [[pdf](https://arxiv.org/pdf/2203.02155.pdf)] 2022.3  
1. 【RLHF】**Augmenting Reinforcement Learning with Human Feedback.** 

    *W. Bradley Knox, Peter Stone* [[pdf](https://www.cs.utexas.edu/~ai-lab/pubs/ICML_IL11-knox.pdf)] 2011.7
1. 【PPO】**Proximal Policy Optimization Algorithms.**  

    *John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov* [[pdf](https://arxiv.org/abs/1707.06347)] 2017.7

1. 【LaMda】 **LaMDA: Language Models for Dialog Applications.**

    *Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Pranesh Srinivasan, Laichee Man, Kathleen Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed Chi, Quoc Le* [[pdf](https://arxiv.org/abs/2201.08239)] 2022.1
    

1. 【Sparrow】 **Improving alignment of dialogue agents via targeted human judgements.**

    *Amelia Glaese, Nat McAleese, Maja Trębacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, Lucy Campbell-Gillingham, Jonathan Uesato, Po-Sen Huang, Ramona Comanescu, Fan Yang, Abigail See, Sumanth Dathathri, Rory Greig, Charlie Chen, Doug Fritz, Jaume Sanchez Elias, Richard Green, Soňa Mokrá, Nicholas Fernando, Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel, William Isaac, John Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, Geoffrey Irving* [[pdf](https://arxiv.org/abs/2209.14375)] 2022.9 

1. **Cross-task generalization via natural language crowdsourcing instructions.**
   
   *Swaroop Mishra, Daniel Khashabi, Chitta Baral, Hannaneh Hajishirzi* [[pdf]](https://aclanthology.org/2022.acl-long.244/) 2021.4

1. **Finetuned language models are zero-shot learners**

    *Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, Quoc V. Le* [[pdf]](https://arxiv.org/abs/2109.01652) 2021.9

1. **Multitask Prompted Training Enables Zero-Shot Task Generalization.**

    *Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Tali Bers, Stella Biderman, Leo Gao, Thomas Wolf, Alexander M. Rush* [[pdf]](https://arxiv.org/abs/2110.08207) 2021.10

1. **Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks.**

    *Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Gary Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Maitreya Patel, Kuntal Kumar Pal, Mehrad Moradshahi, Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Ravsehaj Singh Puri, Rushang Karia, Shailaja Keyur Sampat, Savan Doshi, Siddhartha Mishra, Sujan Reddy, Sumanta Patro, Tanay Dixit, Xudong Shen, Chitta Baral, Yejin Choi, Noah A. Smith, Hannaneh Hajishirzi, Daniel Khashabi* [[pdf]](https://arxiv.org/abs/2204.07705) 2022.4

1. **Putting Humans in the Natural Language Processing Loop: A Survey.**

    *Zijie J. Wang, Dongjin Choi, Shenyu Xu, Diyi Yang* [[pdf](https://aclanthology.org/2021.hcinlp-1.8.pdf)] 2021.4

1. **Scaling Instruction-Finetuned Language Models.**
    
    *Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, Jason Wei* [[pdf]](https://arxiv.org/abs/2210.11416) 2022.10

## Blogs
- [ChatGPT Official Blog](https://openai.com/blog/chatgpt/)  
- [ChatGPTPro](https://chatgpt.pro/) 
- [English version of ChatGPT prompting guide](https://github.com/f/awesome-chatgpt-prompts)  :star::star::star::star::star:
- [Chinese version of ChatGPT prompting guide](https://github.com/PlexPt/awesome-chatgpt-prompts-zh)

## APIs
- [【Non-Official】【Python】 acheong08/ChatGPT ](https://github.com/acheong08/ChatGPT)
- [【Non-Official】【Python】 rawandahmad698/PyChatGPT ](https://github.com/rawandahmad698/PyChatGPT)
- [【Non-Official】【JS/TS】 transitive-bullshit/chatgpt-api ](https://github.com/transitive-bullshit/chatgpt-api)
- [【Non-Official】【Dart】 MisterJimson/chatgpt_api_dart](https://github.com/MisterJimson/chatgpt_api_dart)